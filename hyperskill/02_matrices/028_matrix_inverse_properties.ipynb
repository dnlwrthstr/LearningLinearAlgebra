{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7aeda40b4b8c14f",
   "metadata": {},
   "source": [
    "# Matrix inverse properties\n",
    "The polymath **Henri Poincaré** once said:\n",
    "\n",
    "> *“Mathematics is the art of giving the same name to different things.”*\n",
    "\n",
    "In this section, you will learn the connection between **invertible matrices**, **bases**, and **linear operators**, as well as their **geometric interpretations**. Although they may appear different at first, they are simply **different ways of describing the same underlying concept**.\n",
    "\n",
    "Understanding these relationships will help you gain deeper insight into invertible matrices, grasp more advanced topics, and avoid many unnecessary calculations.\n",
    "\n",
    "In what follows, we will work with a **square matrix** $A$ of size $n \\times n$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e7d36f542a22f4",
   "metadata": {},
   "source": [
    "## Basic Properties\n",
    "\n",
    "The following properties describe how the **inverse of a matrix** behaves with respect to other common matrix operations. These properties are especially useful when computing the inverse of a matrix in terms of a **simpler or related matrix**.\n",
    "\n",
    "If a matrix $A$ is **invertible**, then the following statements hold:\n",
    "\n",
    "- **Inverse of the inverse:** $A^{-1}$ is invertible, and $(A^{-1})^{-1} = A.$\n",
    "\n",
    "- **Scalar multiplication:** For any nonzero real number $c \\neq 0$, the matrix $cA$ is invertible, and $(cA)^{-1} = \\frac{1}{c}\\,A^{-1}.$\n",
    "\n",
    "- **Transpose:** The transpose $A^T$ is invertible, and $(A^T)^{-1} = (A^{-1})^T.$\n",
    "\n",
    "- **Powers of a matrix:** For every positive integer $k$, the matrix $A^k$ is invertible, and $(A^k)^{-1} = (A^{-1})^k.$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c176058ebf7cf2a",
   "metadata": {},
   "source": [
    "### Proof\n",
    "\n",
    "These results follow directly from the **definition of the inverse matrix**. Recall that a matrix $B$ is the inverse of $A$ if and only if $AB = BA = I.$\n",
    "\n",
    "#### Inverse of a scalar multiple\n",
    "\n",
    "For the second property, let $c \\neq 0$. We check that $\\frac{1}{c}A^{-1}$ is the inverse of $cA$:\n",
    "$cA \\left(\\frac{1}{c}A^{-1}\\right) = \\frac{c}{c}(AA^{-1})= I$ and similarly, $\\left(\\frac{1}{c}A^{-1}\\right)cA = \\frac{c}{c}(A^{-1}A) = I.$ Hence, $(cA)^{-1} = \\frac{1}{c}A^{-1}.$\n",
    "\n",
    "#### Inverse of the transpose\n",
    "\n",
    "For the third property, observe that $A^T (A^{-1})^T = (A^{-1}A)^T = I^T = I$ and likewise, $(A^{-1})^T A^T = (AA^{-1})^T= I.$ Therefore, $(A^T)^{-1} = (A^{-1})^T.$\n",
    "\n",
    "#### Inverse of a power\n",
    "\n",
    "Finally, consider the matrix power $A^k$ for a positive integer $k$. We compute $A^k (A^{-1})^k = A^{k-1} A A^{-1} (A^{-1})^{k-1} = A^{k-1} (A^{-1})^{k-1} = \\cdots = A A^{-1} = I$\n",
    "\n",
    "A similar computation shows that $(A^{-1})^k A^k = I$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc44e6ba07f75389",
   "metadata": {},
   "source": [
    "## Example: Using Scalar Properties\n",
    "\n",
    "Suppose you want to find the inverse of the following matrix: $$\n",
    "B =\n",
    "\\begin{pmatrix}\n",
    "2 & 4 \\\\\n",
    "6 & 2\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Since all its entries are even, you can factor out the scalar $2$:\n",
    "$$\n",
    "B = 2\n",
    "\\begin{pmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 1\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Let us denote the inner matrix by\n",
    "$$\n",
    "C =\n",
    "\\begin{pmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 1\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "This matrix is easier to invert. Its inverse is\n",
    "$$\n",
    "C^{-1}\n",
    "= \\frac{1}{5}\n",
    "\\begin{pmatrix}\n",
    "-1 & 2 \\\\\n",
    "3 & -1\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Using the property of inverses for scalar multiples, we obtain\n",
    "$$\n",
    "B^{-1}\n",
    "= (2C)^{-1}\n",
    "= \\frac{1}{2} C^{-1}\n",
    "= \\frac{1}{10}\n",
    "\\begin{pmatrix}\n",
    "-1 & 2 \\\\\n",
    "3 & -1\n",
    "\\end{pmatrix}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923fd8a17278b271",
   "metadata": {},
   "source": [
    "## Systems of Linear Equations\n",
    "\n",
    "So far, you know that when a matrix is **invertible**, any system of equations in which it appears has a **unique solution**. Now, we will look at several **equivalent conditions** that are often easier to check when determining whether a matrix is invertible.\n",
    "\n",
    "Let $A$ be an $n \\times n$ matrix. The following statements are **equivalent**:\n",
    "\n",
    "1. The matrix $A$ is **invertible**.\n",
    "\n",
    "2. The linear system $Ax = b$ has a solution for **all** $b \\in \\mathbb{R}^n$.\n",
    "\n",
    "3. The linear system $Ax = b$ has a **unique solution** for all $b \\in \\mathbb{R}^n$.\n",
    "\n",
    "4. The homogeneous linear system $Ax = 0$has a **unique solution**, namely the trivial one $x = 0$.\n",
    "\n",
    "### Proof\n",
    "\n",
    "Let us denote the **reduced row echelon form** of $A$ by $R$.\n",
    "\n",
    "We will prove the following implications:\n",
    "- $1 \\Rightarrow 3 \\Rightarrow 4 \\Rightarrow 1$\n",
    "- $1 \\Rightarrow 2 \\Rightarrow 1$\n",
    "\n",
    "Since every statement can be reached from any other, this proves their **equivalence**.\n",
    "\n",
    "\n",
    "#### $1 \\Rightarrow 2$ and $1 \\Rightarrow 3$\n",
    "\n",
    "These implications were shown in the topic dedicated to the **matrix inverse**.\n",
    "If $A$ is invertible, then for any $b \\in \\mathbb{R}^n$, the system $Ax = b$ has the unique solution\n",
    "$$\n",
    "x = A^{-1}b.\n",
    "$$\n",
    "\n",
    "#### $3 \\Rightarrow 4$\n",
    "\n",
    "This implication is immediate: taking $b = 0$ in $Ax = b$ gives the homogeneous system\n",
    "$$\n",
    "Ax = 0,\n",
    "$$\n",
    "which therefore has a unique solution.\n",
    "\n",
    "#### $4 \\Rightarrow 1$\n",
    "\n",
    "Consider the homogeneous system\n",
    "$$\n",
    "Ax = 0\n",
    "$$\n",
    "and write it in augmented matrix form:\n",
    "$$\n",
    "[A \\mid 0].\n",
    "$$\n",
    "\n",
    "Applying row operations to reduce $A$ to its reduced row echelon form $R$, the augmented matrix becomes\n",
    "$$\n",
    "[R \\mid 0].\n",
    "$$\n",
    "\n",
    "Since $R$ is square and in reduced row echelon form, if $R \\neq I$, then its last row would consist entirely of zeros. In that case, the system would have **fewer equations than variables**, implying **infinitely many solutions**, which contradicts the assumption that the solution is unique.\n",
    "\n",
    "Therefore,\n",
    "$$\n",
    "R = I,\n",
    "$$\n",
    "which implies that $A$ is invertible.\n",
    "\n",
    "#### $2 \\Rightarrow 1$\n",
    "\n",
    "Consider the system\n",
    "$$\n",
    "Rx = e_n,\n",
    "$$\n",
    "where $e_n$ is the $n$-th standard basis vector, and write its augmented matrix as\n",
    "$$\n",
    "[R \\mid e_n].\n",
    "$$\n",
    "\n",
    "Now apply row operations to transform $R$ back into $A$. These same operations transform $e_n$ into some vector $b$, yielding the augmented matrix\n",
    "$$\n",
    "[A \\mid b].\n",
    "$$\n",
    "\n",
    "If $R \\neq I$, then the last row of $R$ would be zero, and the system $Rx = e_n$ would have **no solution**, implying that $Ax = b$ also has no solution. This contradicts the assumption that $Ax = b$ has a solution for all $b \\in \\mathbb{R}^n$.\n",
    "\n",
    "Hence,\n",
    "$$\n",
    "R = I,\n",
    "$$\n",
    "and therefore $A$ is invertible.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "All four statements are equivalent. Any one of them can be used as a criterion for determining whether a matrix is **invertible**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ab582ec88467f",
   "metadata": {},
   "source": [
    "This means that it is sufficient to guarantee that the **homogeneous system** $Ax = 0$ has a **unique solution** (the trivial one) in order to be able to solve **every system**\n",
    "$Ax = b$ for each possible $b \\in \\mathbb{R}^n$. Let us now look at a **geometric interpretation** of this result using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1d4654c074f9d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T21:38:58.144905Z",
     "start_time": "2025-12-19T21:38:58.064075Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_transformation(A, title=\"Matrix Transformation\"):\n",
    "    # Create a grid of points (the unit square)\n",
    "    square = np.array([\n",
    "        [0, 0], [1, 0], [1, 1], [0, 1], [0, 0]\n",
    "    ]).T\n",
    "    \n",
    "    # Apply transformation\n",
    "    transformed_square = A @ square\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    # Plot original unit square\n",
    "    plt.plot(square[0, :], square[1, :], color='blue', linestyle='--', label='Original Basis (I)')\n",
    "    plt.fill(square[0, :], square[1, :], color='blue', alpha=0.1)\n",
    "    \n",
    "    # Plot transformed square (parallelogram)\n",
    "    plt.plot(transformed_square[0, :], transformed_square[1, :], color='red', label='Transformed Basis (A)')\n",
    "    plt.fill(transformed_square[0, :], transformed_square[1, :], color='red', alpha=0.2)\n",
    "    \n",
    "    # Plot basis vectors as arrows\n",
    "    origin = [0], [0]\n",
    "    plt.quiver(*origin, A[0, 0], A[1, 0], color='red', angles='xy', scale_units='xy', scale=1, label='Av₁')\n",
    "    plt.quiver(*origin, A[0, 1], A[1, 1], color='darkred', angles='xy', scale_units='xy', scale=1, label='Av₂')\n",
    "\n",
    "    plt.axhline(0, color='black', lw=1)\n",
    "    plt.axvline(0, color='black', lw=1)\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "# Using matrix C from the example above\n",
    "C = np.array([[1, 2], [3, 1]])\n",
    "plot_transformation(C, title=\"Invertible Transformation: Area is non-zero\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de58cf165eb47285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:34:39.338325Z",
     "start_time": "2025-12-19T16:34:39.301089Z"
    }
   },
   "source": [
    "## A Quick Test of Invertibility\n",
    "\n",
    "It is time to analyze the relationship between **invertibility** and the **columns of a matrix**. The key observation is that the homogeneous linear system\n",
    "$$\n",
    "Ax = 0\n",
    "$$\n",
    "can be rewritten in terms of the columns of $A$ as\n",
    "$$\n",
    "A_1 x_1 + A_2 x_2 + \\cdots + A_n x_n = 0,\n",
    "$$\n",
    "where $A_1, A_2, \\ldots, A_n$ denote the columns of $A$.\n",
    "\n",
    "Recall that the vectors\n",
    "$$\n",
    "A_1, A_2, \\ldots, A_n\n",
    "$$\n",
    "are **linearly independent** if and only if\n",
    "$$\n",
    "x_1 = x_2 = \\cdots = x_n = 0.\n",
    "$$\n",
    "\n",
    "Notice that this condition is exactly the statement that $0$ is the **only solution** of the system $Ax = 0$. You have already seen that this is equivalent to $A$ being **invertible**. This leads to the following result.\n",
    "\n",
    "\n",
    "## Equivalent Conditions\n",
    "\n",
    "The following conditions are equivalent:\n",
    "\n",
    "- The matrix $A$ is **invertible**.\n",
    "- The columns of $A$ form a **linearly independent set**.\n",
    "- The columns of $A$ form a **basis** of $\\mathbb{R}^n$.\n",
    "\n",
    "Linearly dependent vectors contain **redundant information**, in the sense that one of them can be obtained as a linear combination of the others. Therefore, invertible matrices are precisely those whose columns contain the **minimum amount of information** needed to reconstruct the entire space $\\mathbb{R}^n$.\n",
    "\n",
    "### Determinant Test for Invertibility\n",
    "\n",
    "By now, you are familiar with many properties of invertible matrices. You know how to compute them and how to interpret them geometrically. But how can you quickly determine whether a matrix is invertible?\n",
    "\n",
    "Although checking whether the columns are linearly independent is conceptually simple, there is a **more direct and widely used criterion**:\n",
    "\n",
    "$$\n",
    "A \\text{ is invertible if and only if } \\det(A) \\neq 0.\n",
    "$$\n",
    "\n",
    "\n",
    "#### Proof\n",
    "\n",
    "The determinant detects **linear independence**. That is, the columns of $A$ are linearly independent if and only if\n",
    "$$\n",
    "\\det(A) \\neq 0.\n",
    "$$\n",
    "As shown above, linear independence of the columns is equivalent to $A$ being invertible.\n",
    "This completes the proof. \\(\\blacksquare\\)\n",
    "\n",
    "#### Example\n",
    "\n",
    "Consider the following matrices:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "2 & 1 & 3 \\\\\n",
    "0 & 4 & -1 \\\\\n",
    "1 & -2 & 0\n",
    "\\end{pmatrix},\n",
    "\\qquad\n",
    "\\begin{pmatrix}\n",
    "3 & 0 & 1 \\\\\n",
    "2 & 1 & -2 \\\\\n",
    "0 & 4 & 3\n",
    "\\end{pmatrix},\n",
    "\\qquad\n",
    "\\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "The determinants of the first two matrices are $-17$ and $41$, respectively, so **both are invertible**.\n",
    "The determinant of the third matrix is $0$, so it is **not invertible**.\n",
    "\n",
    "Quick and straightforward.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c108f7744eb1aebe",
   "metadata": {},
   "source": [
    "## The Geometry of Invertible Matrices\n",
    "\n",
    "The characterization of invertibility can be reformulated in terms of the **linear transformation**\n",
    "$L_A$ associated with a matrix $A$.\n",
    "\n",
    "In particular, the condition that the columns of $A$ form a basis means that for every\n",
    "$b \\in \\mathbb{R}^n$ there exists a **unique**\n",
    "$x \\in \\mathbb{R}^n$ such that $L_A(x) = b.$\n",
    "\n",
    "By definition, this means that the transformation $L_A$ is **bijective**. In turn, this is equivalent to $L_A$ being an **invertible function**. This leads to one of the most important relationships between matrices and linear transformations:\n",
    "\n",
    "> **A matrix $A$ is invertible if and only if the linear transformation $L_A$ is invertible.**\n",
    "\n",
    "### Geometric Interpretation\n",
    "\n",
    "From a geometric point of view, invertible matrices exhibit the **best possible behavior**:\n",
    "\n",
    "- $L_A$ is **injective**: it does not send different vectors to the same vector.\n",
    "- $L_A$ is **surjective**: it covers the entire space $\\mathbb{R}^n$.\n",
    "\n",
    "As a result, an invertible matrix can be seen as a transformation that **reassigns the position of every point in space**. Each point moves, but **no two points end up at the same location**. One can think of invertible linear operators as *“shaking”* the space without tearing or collapsing it.\n",
    "\n",
    "\n",
    "### Non-invertible vs. Invertible Operators\n",
    "\n",
    "- A **non-invertible** matrix of size $3 \\times 3$ has an associated operator in $\\mathbb{R}^3$ that **collapses space** into a lower-dimensional object: a point, a line, or a plane.\n",
    "\n",
    "- An **invertible** operator, on the other hand, does **not collapse space**. It only changes the positions of points while preserving the dimensional structure of the space.\n",
    "\n",
    "This geometric distinction highlights why invertibility is such a fundamental concept in linear algebra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a9e904197bfd4",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "You have developed many **equivalent characterizations** of matrix invertibility. Let us summarize them.\n",
    "\n",
    "A square matrix $A$ is **invertible if and only if**:\n",
    "\n",
    "- The linear system $Ax = b$ has a **unique solution** for all $b \\in \\mathbb{R}^n$.\n",
    "\n",
    "- The linear operator $L_A$ is **invertible**.\n",
    "\n",
    "- The **columns of $A$ form a basis** of $\\mathbb{R}^n$.\n",
    "\n",
    "- The determinant of $A$ is nonzero: $\\det(A) \\neq 0.$\n",
    "\n",
    "\n",
    "Useful Properties of the Inverse\n",
    "\n",
    "The inverse of a matrix satisfies the following properties:\n",
    "\n",
    "- **Scalar multiplication:** For any nonzero real number $c \\neq 0$, $(cA)^{-1} = \\frac{1}{c} A^{-1}.$\n",
    "\n",
    "- **Transpose:** $(A^T)^{-1} = (A^{-1})^T.$\n",
    "\n",
    "- **Powers of a matrix:** For every positive integer $k$,$(A^k)^{-1} = (A^{-1})^k.$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
