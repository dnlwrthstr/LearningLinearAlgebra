{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a01e146c5309f1c",
   "metadata": {},
   "source": [
    "# Understanding the Singular Value Decomposition (SVD)\n",
    "\n",
    "## 1. The Basic Idea\n",
    "\n",
    "For any $m×n$ matrix A, there exist matrices U, Σ, and V such that\n",
    "$$\n",
    "A = U\\,\\Sigma\\,V^{\\mathsf T}\n",
    "$$\n",
    "\n",
    "Where\n",
    "- $U$ is an $m \\times m$  **orthogonal** matrix,\n",
    "- $V$ is an $n \\times n$ **orthogonal** matrix,\n",
    "- $Σ$ is an $m \\times n$ **diagonal** matrix with non-negative entries.\n",
    "\n",
    "Orthogonal means\n",
    "- Columns are orthonormal vectors\n",
    "- $U^{\\mathsf T}U = I, \\qquad V^{\\mathsf T}V = I$\n",
    "- Multiplying by U or V is like a rotation and possibly reflection: it preserves lengths and angles\n",
    "\n",
    "\"Diagonal\" for a rectangular matrix $Σ$ means: all off-diagonal entries are zero, only positions $(1,1), (2,2)$, $\\dots$  may be nonzero, up to $\\min(m,n)$.\n",
    "\n",
    "SVD decomposes any linear map into:\n",
    "1. Rotate/reflect the input: $V^{\\mathsf T}$\n",
    "2. Scale along axes: $Σ$\n",
    "3. Rotate/reflect the output: $U$\n",
    "\n",
    "In other words:\n",
    "$$\n",
    "\\text{rotation} \\;\\rightarrow\\; \\text{scaling} \\;\\rightarrow\\; \\text{rotation}.\n",
    "$$\n",
    "\n",
    "## 2. What does this mean geometrically?\n",
    "\n",
    "Think of $A$ as a transformation that takes vectors in $\\mathbb{R}^n$ to vectors in $\\mathbb{R}^m$.\n",
    "\n",
    "SVD says: you can always write that transformation as three simpler steps:\n",
    "\n",
    "$$\n",
    "\\mathbb{R}^n\n",
    "\\;\\xrightarrow{\\;V^{T}\\;}\\;\n",
    "\\mathbb{R}^n\n",
    "\\;\\xrightarrow{\\;\\Sigma\\;}\\;\n",
    "\\mathbb{R}^m\n",
    "\\;\\xrightarrow{\\;U\\;}\\;\n",
    "\\mathbb{R}^m.\n",
    "$$\n",
    "\n",
    "1.\tApply $V^{T}$:\n",
    "\n",
    "    Rotate/reflect the input space (no stretching yet).\n",
    "\n",
    "2. Apply $\\Sigma$:\n",
    "\n",
    "    Stretch/compress along coordinate axes by non-negative factors $\\sigma_1, \\sigma_2, \\dots$ (the diagonal entries). Some directions may be collapsed to zero.\n",
    "\n",
    "3. Applly $U$:\n",
    "\n",
    "    Rotate/reflect the result in the output space.\n",
    "\n",
    "So: SVD decomposes any linear map into rotation → axis-aligned scaling → rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae63bcf13c556a9",
   "metadata": {},
   "source": [
    "## 3. The pieces: $U$, $\\Sigma$, $V$\n",
    "\n",
    "### 3.1 $\\Sigma$: singular values\n",
    "\n",
    "$\\Sigma$ looks like\n",
    "\n",
    "$$\n",
    "\\Sigma = \\begin{pmatrix} \\sigma_1 & 0 & \\dots & 0 \\\\ 0 & \\sigma_2 & \\dots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\dots & \\sigma_r \\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma =\n",
    "\\begin{pmatrix}\n",
    "\\sigma_1 & 0 & \\dots & 0 \\\\\n",
    "0 & \\sigma_2 & \\dots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\dots & \\sigma_r\\\\\n",
    "\\vdots & \\vdots & & \\vdots\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "\n",
    "where $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_r > 0$, remaining entries are 0, r = $\\text{rank}(A)$\n",
    "\n",
    "These $\\sigma_i$ are called the singular values of A.\n",
    "\n",
    "The key fact from the table in your screenshot:\n",
    "\n",
    "Singular values of A are the non-negative square roots of the eigenvalues of $A A^{T}$ (or equivalently of $A^{T} A$; both have the same non-zero eigenvalues).\n",
    "\n",
    "Why?\n",
    "- $A A^{T}$ is $m \\times m$, symmetric and positive semi-definite.\n",
    "- $A^{T} A$ is $n \\times n$, also symmetric and positive semi-definite.\n",
    "- Symmetric positive semi-definite matrices have real, non-negative eigenvalues and an orthonormal basis of eigenvectors.\n",
    "\n",
    "If $\\lambda$ is an eigenvalue of $A^{T}A$, then $\\lambda \\ge 0$, and we define\n",
    "$\\sigma = \\sqrt{\\lambda}$ to be a singular value.\n",
    "\n",
    "So:\n",
    "$$\n",
    "\\sigma_i = \\sqrt{\\lambda_i}, \\quad i = 1, 2, \\dots, r.\n",
    "\\text{eigenvalues of } A^{T}A \\quad \\Rightarrow \\quad \\text{singular values of } A\n",
    "$$\n",
    "\n",
    "## 3.2 Columns of $U$: left singular vectors\n",
    "\n",
    "The columns of $U$ are called the left singular vectors of $A$.\n",
    "\n",
    "From the table:\n",
    "\n",
    "Left singular vectors of A are the eigenvectors of $A A^{T}$.\n",
    "\n",
    "That is, if\n",
    "\n",
    "$$\n",
    "A A^{T} u_i = \\lambda_i u_i,\n",
    "$$\n",
    "then\n",
    "$$\n",
    "u_i = \\text{column } i \\text{ of } U, \\quad\n",
    "\\sigma_i = \\sqrt{\\lambda_i}.\n",
    "$$\n",
    "\n",
    "So the $u_i$'s form an orthonormal basis of $\\mathbb{R}^m$ aligned with how $A$ acts in the output space.\n",
    "\n",
    "\n",
    "## 3.3 Columns of $V$: right singular vectors\n",
    "\n",
    "The columns of V are the right singular vectors of $A$.\n",
    "\n",
    "From the table:\n",
    "\n",
    "Right singular vectors of A are the eigenvectors of $A^{T} A$.\n",
    "\n",
    "So if\n",
    "\n",
    "$A^{T} A v_i = \\lambda_i v_i$,\n",
    "\n",
    "then\n",
    "$$\n",
    "v_i = \\text{column } i \\text{ of } V, \\quad\n",
    "\\sigma_i = \\sqrt{\\lambda_i}.\n",
    "$$\n",
    "The $v_i$’s form an orthonormal basis of $\\mathbb{R}^n$ aligned with the important directions in the input space.\n",
    "\n",
    "\n",
    "## 4. How the pieces relate: the core SVD identity\n",
    "\n",
    "For each nonzero singular value $\\sigma_i$, we have a pair of unit vectors $u_i$ and $v_i$ such that\n",
    "$$\n",
    "A v_i = \\sigma_i u_i.\n",
    "$$\n",
    "This is the essence of SVD:\n",
    "\t•\t$v_i$ is a direction in the input space.\n",
    "\t•\tA sends that direction to the output direction $u_i$, scaled by $\\sigma_i$.\n",
    "\n",
    "In matrix form, you can write:\n",
    "$$\n",
    "A = \\sum_{i=1}^{r} \\sigma_i \\, u_i v_i^{T}.\n",
    "$$\n",
    "This is a sum of rank-1 matrices, each stretching one input direction into one output direction.\n",
    "\n",
    "\n",
    "## 5. Why this is “the best decomposition”\n",
    "\n",
    "People often say **SVD is the “best” decomposition** because:\n",
    "\n",
    "1. **Works for any matrix**\n",
    "\n",
    "   Square, rectangular, singular, fat, tall — SVD always exists.\n",
    "\n",
    "2. **Reveals the rank**\n",
    "\n",
    "   The number of nonzero singular values\n",
    "\n",
    "   $$\n",
    "   \\sigma_i \\neq 0\n",
    "   $$\n",
    "   is exactly the **rank** of $A$.\n",
    "\n",
    "3. **Gives the optimal low-rank approximation**\n",
    "\n",
    "   If you keep only the largest $k$ singular values and their singular vectors,\n",
    "   you obtain the **best possible rank-$k$** approximation of $A$ in the sense of minimizing\n",
    "   $$\n",
    "   |A - A_k|_2 \\quad \\text{and} \\quad \\|A - A_k\\|_F.\n",
    "   $$\n",
    "\n",
    "   This is the **Eckart–Young–Mirsky theorem**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c711a1b405fdcc91",
   "metadata": {},
   "source": [
    "## Computing $AA^T$ and $A^T A$\n",
    "\n",
    "We calculate the products of the matrix with its transpose.\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix} 3 & 0 \\\\ -1 & 2 \\end{pmatrix}, \\quad\n",
    "A^T = \\begin{pmatrix} 3 & -1 \\\\ 0 & 2 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**1. Compute $A A^T$:**\n",
    "\n",
    "$$\n",
    "A A^T =\n",
    "\\begin{pmatrix} 3 & 0 \\\\ -1 & 2 \\end{pmatrix}\n",
    "\\begin{pmatrix} 3 & -1 \\\\ 0 & 2 \\end{pmatrix}\n",
    "= \\begin{pmatrix} 9 & -3 \\\\ -3 & 5 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**2. Compute $A^T A$:**\n",
    "\n",
    "$$\n",
    "A^T A =\n",
    "\\begin{pmatrix} 3 & -1 \\\\ 0 & 2 \\end{pmatrix}\n",
    "\\begin{pmatrix} 3 & 0 \\\\ -1 & 2 \\end{pmatrix}\n",
    "= \\begin{pmatrix} 10 & -2 \\\\ -2 & 4 \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c04796283c9031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T15:34:16.477129Z",
     "start_time": "2025-11-22T15:34:16.468680Z"
    }
   },
   "outputs": [],
   "source": [
    "A = [[3, 0],[-1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a613b12eb7eefe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T15:37:20.004251Z",
     "start_time": "2025-11-22T15:37:19.989375Z"
    }
   },
   "outputs": [],
   "source": [
    "A = np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6666ad00501d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T15:38:46.096150Z",
     "start_time": "2025-11-22T15:38:46.083640Z"
    }
   },
   "outputs": [],
   "source": [
    "A_At = A @ A.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655635b66767d074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T15:38:56.638701Z",
     "start_time": "2025-11-22T15:38:56.598082Z"
    }
   },
   "outputs": [],
   "source": [
    "A_At"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082ef5aa9c7b753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T15:40:18.620774Z",
     "start_time": "2025-11-22T15:40:18.602129Z"
    }
   },
   "outputs": [],
   "source": [
    "At_A = A.transpose() @ A\n",
    "At_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb53a66e184521",
   "metadata": {},
   "source": [
    "## Finding the Eigenvalues\n",
    "\n",
    "Since $A A^T$ and $A^T A$ share the same non-zero eigenvalues, we can solve the characteristic equation for one of them, say $A^T A$.\n",
    "\n",
    "$$\n",
    "A^T A = \\begin{pmatrix} 10 & -2 \\\\ -2 & 4 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**1. Characteristic Equation:**\n",
    "\n",
    "We find $\\lambda$ such that $\\det(A^T A - \\lambda I) = 0$:\n",
    "\n",
    "$$\n",
    "\\det \\begin{pmatrix} 10 - \\lambda & -2 \\\\ -2 & 4 - \\lambda \\end{pmatrix} = 0\n",
    "$$\n",
    "\n",
    "**2. Compute Determinant:**\n",
    "\n",
    "$$\n",
    "(10 - \\lambda)(4 - \\lambda) - (-2)(-2) = 0 \\\\\n",
    "40 - 14\\lambda + \\lambda^2 - 4 = 0 \\\\\n",
    "\\lambda^2 - 14\\lambda + 36 = 0\n",
    "$$\n",
    "\n",
    "**3. Solve Quadratic:**\n",
    "\n",
    "Using the quadratic formula $\\lambda = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\n",
    "\n",
    "$$\n",
    "\\lambda = \\frac{14 \\pm \\sqrt{196 - 144}}{2} = \\frac{14 \\pm \\sqrt{52}}{2} = 7 \\pm \\sqrt{13}\n",
    "$$\n",
    "\n",
    "So the exact eigenvalues are:\n",
    "\n",
    "$$\n",
    "\\lambda_1 = 7 + \\sqrt{13} \\approx 10.606\n",
    "$$\n",
    "$$\n",
    "\\lambda_2 = 7 - \\sqrt{13} \\approx 3.394\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47395adf76a9e858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T15:48:47.446155Z",
     "start_time": "2025-11-22T15:48:47.413219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute eigenvalues for both matrices\n",
    "# Note: They should be identical (except for numerical precision issues)\n",
    "evals_A_At = np.linalg.eigvals(A_At)\n",
    "evals_At_A = np.linalg.eigvals(At_A)\n",
    "\n",
    "print(\"Eigenvalues of A A^T:\", np.sort(evals_A_At)[::-1])\n",
    "print(\"Eigenvalues of A^T A:\", np.sort(evals_At_A)[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6431268ea5dcc0cc",
   "metadata": {},
   "source": [
    "We found that the eigenvalues of both $A A^{T}$ and $A^{T} A$ are\n",
    "$$\n",
    "\\lambda_1 = 7 + \\sqrt{13} \\approx 10.60555128, \\qquad\n",
    "\\lambda_2 = 7 - \\sqrt{13} \\approx 3.39444872.\n",
    "$$\n",
    "\n",
    "The singular values are the non‑negative square roots of these eigenvalues:\n",
    "$$\n",
    "\\sigma_1 = \\sqrt{\\lambda_1} = \\sqrt{7 + \\sqrt{13}}, \\qquad\n",
    "\\sigma_2 = \\sqrt{\\lambda_2} = \\sqrt{7 - \\sqrt{13}}.\n",
    "$$\n",
    "\n",
    "Numerically,\n",
    "$$\n",
    "\\sigma_1 \\approx \\sqrt{10.60555128} \\approx 3.2573,\n",
    "\\qquad\n",
    "\\sigma_2 \\approx \\sqrt{3.39444872} \\approx 1.8410.\n",
    "$$\n",
    "\n",
    "Putting these into the diagonal of $\\Sigma$, we get\n",
    "$$\n",
    "\\Sigma =\n",
    "\\begin{pmatrix}\n",
    "\\sigma_1 & 0 \\\\\n",
    "0 & \\sigma_2\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\sqrt{7 + \\sqrt{13}} & 0 \\\\\n",
    "0 & \\sqrt{7 - \\sqrt{13}}\n",
    "\\end{pmatrix}\n",
    "\\approx\n",
    "\\begin{pmatrix}\n",
    "3.2573 & 0 \\\\\n",
    "0 & 1.8410\n",
    "\\end{pmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7736e9787f316",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T16:34:29.309271Z",
     "start_time": "2025-11-22T16:34:29.294495Z"
    }
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd5d461ac726e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T16:36:59.713801Z",
     "start_time": "2025-11-22T16:36:59.699639Z"
    }
   },
   "outputs": [],
   "source": [
    "Σ = np.array([[math.sqrt(evals_A_At[0]), 0], [0, math.sqrt(evals_A_At[1])]])\n",
    "Σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f044c29762beca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T16:43:42.835045Z",
     "start_time": "2025-11-22T16:43:42.802288Z"
    }
   },
   "outputs": [],
   "source": [
    "eigvals, U = np.linalg.eig(A_At)\n",
    "\n",
    "print(\"Eigenvalues:\\n\", eigvals)\n",
    "print(\"\\nEigenvectors (columns):\\n\", U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d0571242d430c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T16:45:14.165637Z",
     "start_time": "2025-11-22T16:45:14.149618Z"
    }
   },
   "outputs": [],
   "source": [
    "eigvals, V = np.linalg.eig(At_A)\n",
    "\n",
    "print(\"Eigenvalues:\\n\", eigvals)\n",
    "print(\"\\nEigenvectors (columns):\\n\", U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffc11ced208273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T16:47:14.612970Z",
     "start_time": "2025-11-22T16:47:14.594551Z"
    }
   },
   "outputs": [],
   "source": [
    "A_ = U @ Σ @ V.transpose()\n",
    "A_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
