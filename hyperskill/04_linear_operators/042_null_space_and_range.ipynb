{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba7028badbc9eb4",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Null space and range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ccbd4446111a68",
   "metadata": {},
   "source": [
    "Now that you know what linear transformations are, you are ready to delve deeper into their properties. We are going to introduce two new sets that are intimately related to them: the **null space** and the **image**. Both arise naturally in the context of systems of equations.\n",
    "\n",
    "Thanks to them, you will be able to reinterpret these systems, discover several relevant facts about them, and even analyze them geometrically. Here, you will work with a linear transformation $T$ between two vector spaces $V$ and $W$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5531ccace64c45",
   "metadata": {},
   "source": [
    "## Null space\n",
    "\n",
    "Let us look at an $m \\times n$ homogeneous system of linear equations. You already know that it can be represented as a matrix equation\n",
    "\n",
    "$Ax = 0$.\n",
    "\n",
    "If you recall the linear transformation $L_A$ associated with the matrix $A$, which is defined by $L_A(x) = Ax$, then the equation can be written as\n",
    "\n",
    "$L_A(x) = 0$.\n",
    "\n",
    "Thus, the solutions of $Ax = 0$ are precisely the vectors that the transformation $L_A$ maps to $0$. For any linear transformation $T$, the set of such vectors plays an important role and is called the **null space** (or **kernel**) of $T$:\n",
    "\n",
    "$\\ker(T) = \\{\\, v \\in V : T(v) = 0 \\,\\}$.\n",
    "\n",
    "The null space has many interesting properties. The first one is that it is not just a set, but a **subspace**.\n",
    "\n",
    "### Proof that $\\ker(T)$ is a subspace\n",
    "\n",
    "If $v, u \\in \\ker(T)$, then $T(v) = T(u) = 0$. It follows that\n",
    "\n",
    "$T(u + v) = T(u) + T(v) = 0 + 0 = 0$,\n",
    "\n",
    "so $u + v \\in \\ker(T)$. Similarly,\n",
    "\n",
    "$T(\\lambda v) = \\lambda T(v) = \\lambda 0 = 0$,\n",
    "\n",
    "which implies $\\lambda v \\in \\ker(T)$.\n",
    "$\\blacksquare$\n",
    "\n",
    "\n",
    "Returning to systems of linear equations, this shows that the solutions of the homogeneous system $Ax = 0$ are exactly the null space of $L_A$.\n",
    "\n",
    "Now consider the matrix\n",
    "\n",
    "$A =\n",
    "\\begin{pmatrix}\n",
    "6 & 2 & 8 \\\\\n",
    "15 & 5 & 20\n",
    "\\end{pmatrix}$.\n",
    "\n",
    "You can find the solutions of $Ax = 0$ by computing a row-echelon form of $A$. Doing so, you obtain\n",
    "\n",
    "$\\ker(L_A) = \\{\\, \\lambda(-1, 3, 0) + \\mu(-4, 0, 3) : \\lambda, \\mu \\in \\mathbb{R} \\,\\}$.\n",
    "\n",
    "This means that $(-1, 3, 0)^T$ and $(-4, 0, 3)^T$ form a basis of the null space. Hence, the null space of $L_A$ is a plane.\n",
    "\n",
    "$\\ker(L_A) = \\operatorname{span}\\{(-1, 3, 0), (-4, 0, 3)\\}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4fe806037e9fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T17:19:34.603249Z",
     "start_time": "2026-01-02T17:19:34.379133Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# ============================\n",
    "# LEFT: Null space (parameter space)\n",
    "# ============================\n",
    "ax = axes[0]\n",
    "\n",
    "# Parameter grid (λ, μ)\n",
    "lam = np.linspace(-2, 2, 20)\n",
    "mu  = np.linspace(-2, 2, 20)\n",
    "L, M = np.meshgrid(lam, mu)\n",
    "\n",
    "# Draw the plane as a filled region\n",
    "ax.scatter(L, M, s=12, alpha=0.6)\n",
    "\n",
    "# Basis directions in parameter space\n",
    "ax.arrow(0, 0, 1, 0, head_width=0.1, length_includes_head=True)\n",
    "ax.arrow(0, 0, 0, 1, head_width=0.1, length_includes_head=True)\n",
    "\n",
    "ax.text(1.05, 0, r\"$\\lambda$\", fontsize=12)\n",
    "ax.text(0, 1.05, r\"$\\mu$\", fontsize=12)\n",
    "\n",
    "ax.text(-1.8, 1.6,\n",
    "        r\"$\\ker(L_A)$\",\n",
    "        fontsize=13)\n",
    "\n",
    "ax.text(-1.8, 1.2,\n",
    "        r\"$x=\\lambda(-1,3,0)+\\mu(-4,0,3)$\",\n",
    "        fontsize=11)\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlim(-2.2, 2.2)\n",
    "ax.set_ylim(-2.2, 2.2)\n",
    "\n",
    "ax.set_xlabel(r\"$\\lambda$\")\n",
    "ax.set_ylabel(r\"$\\mu$\")\n",
    "ax.set_title(\"Null space (2D plane of solutions)\")\n",
    "ax.grid(True)\n",
    "\n",
    "# ============================\n",
    "# RIGHT: Image under L_A\n",
    "# ============================\n",
    "ax = axes[1]\n",
    "\n",
    "# Single point at the origin\n",
    "ax.scatter(0, 0, s=120, color=\"#ffcc00\")\n",
    "ax.text(0.05, 0.05, r\"$0$\", fontsize=12)\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "\n",
    "ax.set_xlabel(\"output coordinate\")\n",
    "ax.set_ylabel(\"output coordinate\")\n",
    "ax.set_title(r\"Image under $L_A$: all $\\rightarrow 0$\")\n",
    "ax.grid(True)\n",
    "\n",
    "# ============================\n",
    "# Arrow indicating the map\n",
    "# ============================\n",
    "fig.text(0.5, 0.5,\n",
    "         r\"$\\Longrightarrow\\quad L_A \\quad\\Longrightarrow$\",\n",
    "         ha=\"center\", va=\"center\", fontsize=14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f16992d01d92df",
   "metadata": {},
   "source": [
    "## Null space properties\n",
    "\n",
    "Transformations that send different vectors to different vectors are called **injective**. This means that the unique vector that can be mapped to $0$ is indeed $0$. Consequently,\n",
    "\n",
    "$\\ker(T) = \\{0\\}$.\n",
    "\n",
    "Thus, injective transformations have the smallest possible null space.\n",
    "\n",
    "It is intuitive that the more vectors $T$ maps to $0$, the less injective it is. This suggests that when the null space is as small as possible, $T$ is injective. This intuition is correct, and it leads to the following result:\n",
    "\n",
    "$T$ is injective if and only if $\\ker(T) = \\{0\\}$.\n",
    "\n",
    "### Proof\n",
    "\n",
    "We have already shown that if $T$ is injective, then its null space contains only $0$.\n",
    "\n",
    "Conversely, if $T(v) = T(u)$, then $T(v) - T(u) = 0$, which implies $T(u - v) = 0$. By definition, this means that $u - v \\in \\ker(T)$. By hypothesis, the only vector in the null space is $0$, so $u - v = 0$, and therefore $u = v$.\n",
    "$\\blacksquare$\n",
    "\n",
    "This result means that, to prove that $T$ is injective, it is enough to show that $T(v) = 0$ implies $v = 0$.\n",
    "\n",
    "Linear transformations preserve the structure of vector spaces. The third consequence is that transformations whose null space is as small as possible preserve linear independence. More precisely, if $v_1, \\ldots, v_k$ are linearly independent and $T$ is injective, then $T(v_1), \\ldots, T(v_k)$ are linearly independent.\n",
    "\n",
    "### Proof\n",
    "\n",
    "Assume $v_1, \\ldots, v_k$ are linearly independent and consider\n",
    "\n",
    "$\\lambda_1 T(v_1) + \\cdots + \\lambda_k T(v_k) = 0$.\n",
    "\n",
    "This implies\n",
    "\n",
    "$T(\\lambda_1 v_1 + \\cdots + \\lambda_k v_k) = 0$.\n",
    "\n",
    "Since $T$ is injective, it follows that\n",
    "\n",
    "$\\lambda_1 v_1 + \\cdots + \\lambda_k v_k = 0$.\n",
    "\n",
    "Because the vectors are linearly independent, we conclude that\n",
    "\n",
    "$\\lambda_1 = \\cdots = \\lambda_k = 0$.\n",
    "\n",
    "Hence, $T(v_1), \\ldots, T(v_k)$ are linearly independent.\n",
    "$\\blacksquare$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67c2a3abae9004e",
   "metadata": {},
   "source": [
    "## Range\n",
    "\n",
    "Let us go back to systems of equations. When they are not homogeneous, they look like\n",
    "\n",
    "$Ax = b$.\n",
    "\n",
    "But this is exactly\n",
    "\n",
    "$L_A(x) = b$.\n",
    "\n",
    "This means that there must be a vector $x$ whose image under $T$ is $b$. In general, if you collect the images under $T$ of all vectors in $V$, the result is a set called the **range** (or **image**) of $T$:\n",
    "\n",
    "$\\operatorname{Im}(T) = \\{\\, T(v) : v \\in V \\,\\}$.\n",
    "\n",
    "The range of $T$ has a close relationship with its kernel. Both have similar properties and actually complement each other.\n",
    "\n",
    "To begin with, while the null space contains vectors of $V$, the range is a subset of $W$. And, like the null space, it is a subspace.\n",
    "\n",
    "### Proof\n",
    "\n",
    "If $v, u \\in V$, then $T(v), T(u) \\in \\operatorname{Im}(T)$. Clearly,\n",
    "\n",
    "$T(v) + T(u) = T(v + u)$,\n",
    "\n",
    "and since $v + u \\in V$, we obtain\n",
    "\n",
    "$T(v) + T(u) \\in \\operatorname{Im}(T)$.\n",
    "\n",
    "Similarly, since $\\lambda v \\in V$, it follows that\n",
    "\n",
    "$\\lambda T(v) = T(\\lambda v) \\in \\operatorname{Im}(T)$.\n",
    "$\\blacksquare$\n",
    "\n",
    "\n",
    "If, for example, $T$ is a transformation from $\\mathbb{R}^4$ into $\\mathbb{R}^3$, then this means that it collapses all of $\\mathbb{R}^4$ into a point, a line, a plane, or even all of $\\mathbb{R}^3$.\n",
    "\n",
    "Now, the system $Ax = b$ has a solution if $L_A(x) = b$, which means that $b \\in \\operatorname{Im}(L_A)$. Therefore, the system of equations $Ax = b$ has a solution if and only if $b$ belongs to $\\operatorname{Im}(L_A)$.\n",
    "\n",
    "Let us continue with the matrix from the first example.\n",
    "\n",
    "$L_A(x)\n",
    "= xL_A(e_1) + yL_A(e_2) + zL_A(e_3)\n",
    "= xAe_1 + yAe_2 + zAe_3\n",
    "= x(6,15) + y(2,5) + z(8,20)\n",
    "= 3x(2,5) + y(2,5) + 4z(2,5)\n",
    "= (3x + y + 4z)(2,5)$.\n",
    "\n",
    "Thus, $(2,5)^T$ generates the range of $L_A$, and therefore the range is a line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946bcae4977de13b",
   "metadata": {},
   "source": [
    "## Range properties\n",
    "\n",
    "Transformations that occupy the entire space $W$ are called **surjective**. This means that\n",
    "\n",
    "$\\operatorname{Im}(T) = W$.\n",
    "\n",
    "In other words, surjective transformations have the largest possible range.\n",
    "\n",
    "Linear transformations preserve **spanning sets**:\n",
    "\n",
    "If $\\operatorname{span}(v_1, v_2, \\ldots, v_n) = V$, then $\\operatorname{span}(T(v_1), T(v_2), \\ldots, T(v_n)) = \\operatorname{Im}(T)$.\n",
    "\n",
    "\n",
    "### Proof\n",
    "\n",
    "If $T(v) \\in \\operatorname{Im}(T)$, then $v \\in V$, and by hypothesis,\n",
    "\n",
    "$v = \\lambda_1 v_1 + \\lambda_2 v_2 + \\cdots + \\lambda_n v_n$.\n",
    "\n",
    "Applying $T$, we obtain\n",
    "\n",
    "$T(v) = T(\\lambda_1 v_1 + \\lambda_2 v_2 + \\cdots + \\lambda_n v_n)\n",
    "= \\lambda_1 T(v_1) + \\lambda_2 T(v_2) + \\cdots + \\lambda_n T(v_n)$.\n",
    "\n",
    "Thus,\n",
    "\n",
    "$T(v) \\in \\operatorname{span}(T(v_1), T(v_2), \\ldots, T(v_n))$.\n",
    "\n",
    "\n",
    "You can use this result to calculate the **rank** of a matrix. Since\n",
    "\n",
    "$L_A(e_i) = A(e_i)$\n",
    "\n",
    "is the $i$-th column of $A$, it follows that the range of $L_A$ is the space spanned by the columns of $A$. The dimension of $\\operatorname{Im}(L_A)$ is called the **rank** of $A$.\n",
    "\n",
    "## Summary\n",
    "\n",
    "Injective transformations have the smallest null space and preserve linear independence.\n",
    "Surjective transformations have the largest range and preserve spanning sets.\n",
    "\n",
    "Putting everything together, **bijective transformations** (injective and surjective at the same time) preserve linearly independent spanning sets. In other words, they map bases of $V$ to bases of $W$. Such transformations are called **isomorphisms**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068acfd073052bf",
   "metadata": {},
   "source": [
    "## Equilibrium\n",
    "\n",
    "Up to this point, it is clear that the kernel and the image tell us several things about the behavior of $T$ and have similar properties.\n",
    "\n",
    "However, their connection is so intimate that they balance each other: the smaller one is, the larger the other. More precisely, since $\\ker(T)$ is a subspace of $V$, it is clear that\n",
    "$\\dim \\ker(T) \\le \\dim V$.\n",
    "It turns out that $\\dim \\operatorname{Im}(T)$ is exactly the quantity that complements $\\dim \\ker(T)$, in the sense that\n",
    "\n",
    "$\\dim \\ker(T) + \\dim \\operatorname{Im}(T) = \\dim V$.\n",
    "\n",
    "This is precisely the content of the last theorem, which is both a theoretical and a practical tool that you will use frequently in the future. It is called the **dimension theorem** (also known as the **fundamental theorem of linear transformations**):\n",
    "\n",
    "$\\dim V = \\dim \\ker(T) + \\dim \\operatorname{Im}(T)$.\n",
    "\n",
    "The dimension theorem combines the dimension of the null space with the dimension of the range.\n",
    "\n",
    "---\n",
    "\n",
    "### Proof\n",
    "\n",
    "Let $\\{v_1, \\ldots, v_m\\}$ be a basis of $\\ker(T)$. We can extend it to a basis of $V$ by adding vectors $\\{u_1, \\ldots, u_n\\}$. Then\n",
    "\n",
    "$\\dim \\ker(T) = m \\quad \\text{and} \\quad \\dim V = m + n$.\n",
    "\n",
    "We will prove that $\\{T(u_1), \\ldots, T(u_n)\\}$ is a basis of $\\operatorname{Im}(T)$.\n",
    "\n",
    "First, it is a spanning set. If $v \\in V$, then there exist scalars $\\lambda_1, \\ldots, \\lambda_m, \\mu_1, \\ldots, \\mu_n \\in \\mathbb{R}$ such that\n",
    "\n",
    "$v = \\lambda_1 v_1 + \\cdots + \\lambda_m v_m + \\mu_1 u_1 + \\cdots + \\mu_n u_n$.\n",
    "\n",
    "Applying $T$, we obtain\n",
    "\n",
    "$T(v)\n",
    "= \\lambda_1 T(v_1) + \\cdots + \\lambda_m T(v_m) + \\mu_1 T(u_1) + \\cdots + \\mu_n T(u_n)\n",
    "= \\mu_1 T(u_1) + \\cdots + \\mu_n T(u_n)$,\n",
    "\n",
    "since $T(v_i) = 0$ for all $i$. Hence, every element of $\\operatorname{Im}(T)$ is a linear combination of $T(u_1), \\ldots, T(u_n)$.\n",
    "\n",
    "Next, we verify linear independence. Suppose\n",
    "\n",
    "$\\mu_1 T(u_1) + \\cdots + \\mu_n T(u_n) = 0$.\n",
    "\n",
    "Then\n",
    "\n",
    "$T(\\mu_1 u_1 + \\cdots + \\mu_n u_n) = 0$,\n",
    "\n",
    "which implies\n",
    "\n",
    "$\\mu_1 u_1 + \\cdots + \\mu_n u_n \\in \\ker(T)$.\n",
    "\n",
    "Since $\\{v_1, \\ldots, v_m\\}$ is a basis of $\\ker(T)$, there exist scalars $\\lambda_1, \\ldots, \\lambda_m$ such that\n",
    "\n",
    "$\\mu_1 u_1 + \\cdots + \\mu_n u_n = \\lambda_1 v_1 + \\cdots + \\lambda_m v_m$.\n",
    "\n",
    "Rearranging,\n",
    "\n",
    "$\\mu_1 u_1 + \\cdots + \\mu_n u_n - \\lambda_1 v_1 - \\cdots - \\lambda_m v_m = 0$.\n",
    "\n",
    "Because $\\{v_1, \\ldots, v_m, u_1, \\ldots, u_n\\}$ is a basis of $V$, all coefficients must be zero, and in particular\n",
    "\n",
    "$\\mu_1 = \\cdots = \\mu_n = 0$.\n",
    "\n",
    "Thus, $\\{T(u_1), \\ldots, T(u_n)\\}$ is linearly independent, and therefore a basis of $\\operatorname{Im}(T)$.\n",
    "\n",
    "---\n",
    "\n",
    "As a first illustration of the power of this theorem, you can easily show that when $\\dim(V) = \\dim(W)$, the following statements are equivalent: $T$ is injective, $T$ is surjective, and $T$ is bijective.\n",
    "\n",
    "Here are some applications to systems of linear equations. It is often easy to determine the null space of $L_A$, and by the Dimension Theorem you can then compute the rank of $A$ and decide whether the image is a line, a plane, or something else.\n",
    "\n",
    "When the matrix is square of size $n \\times n$, the rank can be interpreted as a measure of how likely it is to have unique solutions. The larger the rank, the closer $\\operatorname{Im}(L_A)$ is to $\\mathbb{R}^n$. When $\\operatorname{rank} A = n$, we have $\\operatorname{Im}(L_A) = \\mathbb{R}^n$.\n",
    "\n",
    "From the Dimension Theorem, this means that $L_A$ is bijective, so the equation $L_A(x) = b$ has a unique solution. Equivalently, the system $Ax = b$ has a solution, and that solution is unique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a61b38c29b5c8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The null space of $T$ is\n",
    "\n",
    "$\\ker(T) = \\{\\, v \\in V : T(v) = 0 \\,\\}$.\n",
    "\n",
    "The solutions of a homogeneous system of linear equations are the null space of the matrix of the system.\n",
    "\n",
    "$T$ is injective if and only if $\\ker(T) = \\{0\\}$.\n",
    "\n",
    "The range of $T$ is\n",
    "\n",
    "$\\operatorname{Im}(T) = \\{\\, T(v) : v \\in V \\,\\}$.\n",
    "\n",
    "An inhomogeneous system of linear equations $Ax = b$ has a solution if and only if $b \\in \\operatorname{Im}(L_A)$.\n",
    "\n",
    "$T$ is surjective if and only if $\\operatorname{Im}(T) = W$.\n",
    "\n",
    "The dimension theorem states that\n",
    "\n",
    "$\\dim V = \\dim \\ker(T) + \\dim \\operatorname{Im}(T)$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
