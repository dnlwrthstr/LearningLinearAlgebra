{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba626ec",
   "metadata": {},
   "source": [
    "\n",
    "# Tensor Products and Multilinear Algebra\n",
    "\n",
    "This notebook introduces **tensor products** and **multilinear algebra**, which generalize\n",
    "linear maps to interactions among multiple vector spaces.\n",
    "\n",
    "Tensor products provide the mathematical foundation for:\n",
    "- Multilinear maps\n",
    "- Higher-order data representations\n",
    "- Physics (quantum states, stress/strain)\n",
    "- Machine learning (feature interactions, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0284872",
   "metadata": {},
   "source": [
    "\n",
    "## Mathematical Preliminaries\n",
    "\n",
    "We assume familiarity with:\n",
    "\n",
    "- Vector spaces and bases\n",
    "- Linear maps\n",
    "- Bilinear forms\n",
    "\n",
    "All vector spaces are finite-dimensional unless stated otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1541b1ff",
   "metadata": {},
   "source": [
    "\n",
    "## Multilinear Maps\n",
    "\n",
    "A **multilinear map** is a function\n",
    "\n",
    "$$\n",
    "f : V_1 \\times V_2 \\times \\cdots \\times V_k \\to W\n",
    "$$\n",
    "\n",
    "that is linear in each argument separately.\n",
    "\n",
    "Examples:\n",
    "- Bilinear forms: $V \\times V \\to \\mathbb{R}$\n",
    "- Matrix multiplication: $(A, x) \\mapsto Ax$\n",
    "- Determinants: multilinear in rows or columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3a12c",
   "metadata": {},
   "source": [
    "\n",
    "## Motivation for Tensor Products\n",
    "\n",
    "Multilinear maps are harder to study than linear ones.\n",
    "\n",
    "The tensor product allows us to:\n",
    "\n",
    "> Convert multilinear maps into linear maps on a larger space.\n",
    "\n",
    "Specifically, every bilinear map\n",
    "$$\n",
    "f : V \\times W \\to U\n",
    "$$\n",
    "corresponds uniquely to a linear map\n",
    "$$\n",
    "\\tilde f : V \\otimes W \\to U.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be8c26",
   "metadata": {},
   "source": [
    "\n",
    "## Tensor Product of Vector Spaces\n",
    "\n",
    "Given vector spaces $V$ and $W$, their **tensor product** $V \\otimes W$ is a vector space\n",
    "equipped with a bilinear map\n",
    "\n",
    "$$\n",
    "\\otimes : V \\times W \\to V \\otimes W\n",
    "$$\n",
    "\n",
    "satisfying the universal property:\n",
    "\n",
    "For every bilinear $f : V \\times W \\to U$, there exists a unique linear\n",
    "$\\tilde f : V \\otimes W \\to U$ such that\n",
    "\n",
    "$$\n",
    "f(v,w) = \\tilde f(v \\otimes w).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0432911",
   "metadata": {},
   "source": [
    "\n",
    "## Dimension and Bases\n",
    "\n",
    "If $\\{v_i\\}$ is a basis of $V$ and $\\{w_j\\}$ is a basis of $W$, then\n",
    "\n",
    "$$\n",
    "\\{v_i \\otimes w_j\\}\n",
    "$$\n",
    "\n",
    "is a basis of $V \\otimes W$.\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "\\dim(V \\otimes W) = \\dim(V) \\cdot \\dim(W).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6914850",
   "metadata": {},
   "source": [
    "\n",
    "## Rank-1 (Pure) Tensors\n",
    "\n",
    "Elements of the form\n",
    "\n",
    "$$\n",
    "v \\otimes w\n",
    "$$\n",
    "\n",
    "are called **rank-1** or **pure tensors**.\n",
    "\n",
    "General tensors are linear combinations of pure tensors:\n",
    "\n",
    "$$\n",
    "T = \\sum_{i} v_i \\otimes w_i.\n",
    "$$\n",
    "\n",
    "Tensor rank is more subtle than matrix rank and is hard to compute in general.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0413c9",
   "metadata": {},
   "source": [
    "\n",
    "## Tensor Products and Matrices\n",
    "\n",
    "For finite-dimensional spaces:\n",
    "\n",
    "$$\n",
    "V \\cong \\mathbb{R}^m, \\quad W \\cong \\mathbb{R}^n\n",
    "$$\n",
    "\n",
    "we have:\n",
    "\n",
    "$$\n",
    "V \\otimes W \\cong \\mathbb{R}^{m \\times n}\n",
    "$$\n",
    "\n",
    "via the identification:\n",
    "\n",
    "$$\n",
    "e_i \\otimes e_j \\leftrightarrow E_{ij}\n",
    "$$\n",
    "\n",
    "This connects tensors to matrices, but tensor products extend beyond matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff155f95",
   "metadata": {},
   "source": [
    "\n",
    "## Kronecker Product\n",
    "\n",
    "The **Kronecker product** of matrices $A \\in \\mathbb{R}^{m \\times n}$ and\n",
    "$B \\in \\mathbb{R}^{p \\times q}$ is\n",
    "\n",
    "$$\n",
    "A \\otimes B =\n",
    "\\begin{pmatrix}\n",
    "a_{11}B & \\cdots & a_{1n}B \\\\\n",
    "\\vdots & & \\vdots \\\\\n",
    "a_{m1}B & \\cdots & a_{mn}B\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "This is the matrix representation of the tensor product of linear maps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7149b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T14:19:18.066130Z",
     "start_time": "2025-12-26T14:19:18.047685Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "\n",
    "B = np.array([[0, 5],\n",
    "              [6, 7]])\n",
    "\n",
    "np.kron(A, B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3061e2a",
   "metadata": {},
   "source": [
    "\n",
    "## Higher-Order Tensors\n",
    "\n",
    "Tensor products extend to more than two spaces:\n",
    "\n",
    "$$\n",
    "V_1 \\otimes V_2 \\otimes \\cdots \\otimes V_k\n",
    "$$\n",
    "\n",
    "These objects represent:\n",
    "- Multidimensional arrays\n",
    "- Multilinear interactions\n",
    "- Higher-order correlations\n",
    "\n",
    "They appear in:\n",
    "- Tensor decomposition methods\n",
    "- Deep learning architectures\n",
    "- Physics and chemistry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0c7716",
   "metadata": {},
   "source": [
    "\n",
    "## Practical Notes\n",
    "\n",
    "- Tensor products grow dimensions rapidly\n",
    "- Computations scale exponentially with order\n",
    "- Low-rank tensor approximations are essential in practice\n",
    "- Many algorithms rely on structure exploitation\n",
    "\n",
    "Tensor algebra trades simplicity for expressive power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a8f40",
   "metadata": {},
   "source": [
    "\n",
    "## Summary\n",
    "\n",
    "Key takeaways:\n",
    "\n",
    "- Multilinear maps generalize linear maps\n",
    "- Tensor products linearize multilinear structure\n",
    "- $\\dim(V \\otimes W) = \\dim(V)\\dim(W)$\n",
    "- Pure tensors are rank-1 elements\n",
    "- Kronecker product represents tensor products of matrices\n",
    "- Tensor methods underpin modern ML and physics\n",
    "\n",
    "Next: **Numerical linear algebra**, focusing on stability and computation.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
