{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61ff0b6",
   "metadata": {},
   "source": [
    "\n",
    "# Matrix Decompositions\n",
    "\n",
    "This notebook introduces **matrix decompositions**, which express a matrix as a product of simpler, structured matrices.\n",
    "\n",
    "Matrix decompositions are central to numerical linear algebra, optimization, scientific computing, and machine learning. They transform abstract spectral ideas into **computational tools**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d8373a",
   "metadata": {},
   "source": [
    "\n",
    "## Mathematical Preliminaries\n",
    "\n",
    "We assume familiarity with:\n",
    "\n",
    "- Matrix multiplication\n",
    "- Invertible matrices\n",
    "- Rank and linear independence\n",
    "- Eigenvalues (from Spectral Theory)\n",
    "\n",
    "All matrices are real unless stated otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef39d9a",
   "metadata": {},
   "source": [
    "\n",
    "## Why Decompositions Matter\n",
    "\n",
    "Matrix decompositions allow us to:\n",
    "\n",
    "- Solve linear systems efficiently\n",
    "- Understand matrix structure\n",
    "- Improve numerical stability\n",
    "- Reduce high-dimensional data\n",
    "\n",
    "Core idea:\n",
    "> Complicated matrices become manageable when factored into simple components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a6aac",
   "metadata": {},
   "source": [
    "\n",
    "## LU Decomposition\n",
    "\n",
    "For a square matrix $A$, LU decomposition factors\n",
    "\n",
    "$$\n",
    "A = LU\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $L$ is lower triangular (unit diagonal)\n",
    "- $U$ is upper triangular\n",
    "\n",
    "Used for:\n",
    "- Fast solution of $Ax = b$\n",
    "- Repeated solves with different right-hand sides\n",
    "\n",
    "LU may require **row pivoting** for numerical stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4f555f49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:06:34.612508Z",
     "start_time": "2025-12-26T10:06:33.640672Z"
    }
   },
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "A = np.array([[2., 3., 1.],\n",
    "              [4., 7., 7.],\n",
    "              [-2., 4., 5.]])\n",
    "\n",
    "P, L, U = lu(A)\n",
    "P, L, U\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.]]),\n",
       " array([[ 1.        ,  0.        ,  0.        ],\n",
       "        [-0.5       ,  1.        ,  0.        ],\n",
       "        [ 0.5       , -0.06666667,  1.        ]]),\n",
       " array([[ 4.        ,  7.        ,  7.        ],\n",
       "        [ 0.        ,  7.5       ,  8.5       ],\n",
       "        [ 0.        ,  0.        , -1.93333333]]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "965a93c4",
   "metadata": {},
   "source": [
    "\n",
    "## QR Decomposition\n",
    "\n",
    "Any matrix $A \\in \\mathbb{R}^{m \\times n}$ can be written as\n",
    "\n",
    "$$\n",
    "A = QR\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $Q$ has orthonormal columns\n",
    "- $R$ is upper triangular\n",
    "\n",
    "QR arises from **Gramâ€“Schmidt orthogonalization**.\n",
    "\n",
    "Applications:\n",
    "- Least squares\n",
    "- Numerical stability\n",
    "- Eigenvalue algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c8739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q, R = np.linalg.qr(A)\n",
    "Q, R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c8bbf8",
   "metadata": {},
   "source": [
    "\n",
    "## Cholesky Decomposition\n",
    "\n",
    "If $A$ is **symmetric positive definite**, then\n",
    "\n",
    "$$\n",
    "A = LL^T\n",
    "$$\n",
    "\n",
    "where $L$ is lower triangular.\n",
    "\n",
    "Properties:\n",
    "- Faster than LU\n",
    "- Numerically stable\n",
    "- Requires positive definiteness\n",
    "\n",
    "Common in:\n",
    "- Optimization\n",
    "- Covariance matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a5aaf58f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:08:21.786742Z",
     "start_time": "2025-12-26T10:08:21.749038Z"
    }
   },
   "source": [
    "\n",
    "B = np.array([[4., 2.],\n",
    "              [2., 3.]])\n",
    "\n",
    "L = np.linalg.cholesky(B)\n",
    "L\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.        , 0.        ],\n",
       "       [1.        , 1.41421356]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "b4a3de87",
   "metadata": {},
   "source": [
    "\n",
    "## Singular Value Decomposition (SVD)\n",
    "\n",
    "Every matrix $A \\in \\mathbb{R}^{m \\times n}$ admits\n",
    "\n",
    "$$\n",
    "A = U \\Sigma V^T\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $U$ and $V$ are orthogonal\n",
    "- $\\Sigma$ is diagonal with nonnegative singular values\n",
    "\n",
    "Singular values measure:\n",
    "- Energy\n",
    "- Rank\n",
    "- Conditioning\n",
    "\n",
    "SVD exists **for all matrices**, regardless of shape or rank.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9dc456d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:08:48.649716Z",
     "start_time": "2025-12-26T10:08:48.584433Z"
    }
   },
   "source": [
    "\n",
    "U, s, Vt = np.linalg.svd(A)\n",
    "U, s, Vt\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.26002008,  0.38601219,  0.88508991],\n",
       "        [-0.85032068,  0.34279446, -0.39930778],\n",
       "        [-0.45754159, -0.85643829,  0.2391007 ]]),\n",
       " array([12.43394263,  4.13842873,  1.12715503]),\n",
       " array([[-0.24177687, -0.68863687, -0.68361042],\n",
       "        [ 0.93177364,  0.03185861, -0.3616392 ],\n",
       "        [-0.27081697,  0.72440616, -0.63395101]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "4bfe5c6d",
   "metadata": {},
   "source": [
    "\n",
    "## Geometric Interpretation of SVD\n",
    "\n",
    "SVD decomposes a linear map into:\n",
    "\n",
    "1. Rotation ($V^T$)\n",
    "2. Scaling ($\\Sigma$)\n",
    "3. Rotation ($U$)\n",
    "\n",
    "This explains:\n",
    "- Low-rank approximation\n",
    "- PCA\n",
    "- Pseudoinverses\n",
    "\n",
    "SVD is the most powerful decomposition in applied linear algebra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b51ba",
   "metadata": {},
   "source": [
    "\n",
    "## Failure Modes and Numerical Notes\n",
    "\n",
    "- LU without pivoting may fail\n",
    "- QR is more stable than LU\n",
    "- Cholesky fails if $A$ is not positive definite\n",
    "- SVD is stable but computationally expensive\n",
    "\n",
    "Trade-off:\n",
    "> Stability vs. computational cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900eb39c",
   "metadata": {},
   "source": [
    "\n",
    "## Summary\n",
    "\n",
    "Key takeaways:\n",
    "\n",
    "- Decompositions simplify matrix problems\n",
    "- LU: fast solves\n",
    "- QR: orthogonality and stability\n",
    "- Cholesky: efficient for SPD matrices\n",
    "- SVD: universal and robust\n",
    "\n",
    "Next: **Inner product spaces**, the geometric foundation behind these decompositions.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
